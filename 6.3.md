---
title: "Actuarial Data Science Chapter 6.3"
author: "db"
---

# 6.3. Klassiﬁkations- und Regressionsmethoden

- **Thema**:
  - Vorhersage einer `Zielgröße (y)` durch `Prädiktoren` (Merkmale).
  - Lernen des Zusammenhangs durch Beobachtungen von `Zielgröße` und `Prädiktoren`.

- **Regressionsprobleme**:
  - Zielvariable `y` nimmt kontinuierliche Werte an.
  - Beispiel: Vorhersage von Einkommen.

- **Klassifikationsprobleme**:
  - Zielvariable `y` nimmt endliche Werte an ($y \in \{C_1, ..., C_n\}$).
  - Beispiele: `Storno / kein Storno`, `Spam / kein Spam`.
  - Ausprägungen von `y` werden als `Klassen` bezeichnet.

##  Arten von Variablen

- **Numerische Variablen**:
  - Unterteilung in `diskrete` und `stetige` Variablen.
  - `Diskrete Variablen`: Abzählbare Werte (z.B. Anzahl der Kinder).
  - `Stetige Variablen`:
    - **Intervallskalierte Variablen**: Differenzen haben Bedeutung (z.B. Temperatur in °C).
    - **Verhältnisskalierte Variablen**: Bedeutsame Quotienten und sinnvoller Nullpunkt (z.B. Herzfrequenz).

- **Kategorielle Variablen**:
  - Unterteilung in `ordinalskalierte` und `nominalskalierte` Variablen.
  - **Nominalskalierte Variablen**:
    - Keine lineare Ordnung (z.B. Geschlecht: 0/1 oder M/F).
    - Vorsicht bei mehr als zwei Gruppen, um keine falsche Ordinalordnung zu implizieren.
  - **Ordinalskalierte Variablen**:
    - Ausprägungen können geordnet werden (z.B. Schulnoten).

## 6.3.1. Multiple Lineare Regression

- **Regression:**
  - **Variablen:**
    - p erklärende Variablen $X_1, ..., X_p$
    - Stetige Zielvariable Y
  - **Zusammenhang:**
    - Funktion f: Y = f(X) + ϵ
    - ϵ repräsentiert Störgrößen
    - Annahmen zu ϵ, meist additive Störgrößen

- **Schätzaufgabe:**
  - Beste Schätzung der unbekannten Funktion f
  - Trennung zwischen systematischer Komponente f und Fehler ϵ

- **Beobachtungen:**
  - Bezeichnung der erklärenden Variablen: $x_{ij}$ (j-te Variable der i-ten Beobachtung)

- **Designmatrix X:**
  - $X \in R^{n \times (p+1)}$
  - Zeilenvektoren: $x_i$
  - Spalten: $x_1, ..., x_{p+1}$
  
  $$\left(\begin{matrix}1&x_{11}&\cdots&x_{1p}\\\vdots&\vdots&\ddots&\vdots\\1&x_{n1}&\cdots&x_{np}\\\end{matrix}\right)$$
  
- **Generalisierte Lineare Modelle (GLM):**
  - Anwendung in Risikobewertung und überwachten Lernen
  - Typische Vertreter: lineare, logistische, Poisson-Regression
  - Fokus auf lineares Regressionsproblem

- **Lineares Regressionsmodell:**
  - Modell: Y = Xβ + ϵ
  - **Annahmen:**
    - E(ϵ) = 0 (Störungen im Mittel 0)
    - Var(ϵ) = σ² (konstante Varianz, homoskedastische Fehler)
    - $Cov(\epsilon_i, \epsilon_j)$ = 0 für i ≠ j (unkorrelierte Störgrößen)
    - Normalverteilte Fehler: $\epsilon \sim N(0, \sigma^2I)$

  - **Eigenschaften:**
    - $E(Y_i) = \beta_0 + \beta_1x_{i1} + ... + \beta_p x_{ip}$
    - $Var(Y_i) = \sigma^2$
    - $Cov(Y_i, Y_j) = 0$ für i ≠ j

  - **Matrixnotation:**
    - E(Y) = Xβ
    - Cov(Y) = σ²I
    - Normalverteiltes Y: $Y \sim N(X\beta , \sigma^2I)$

- **Bedingung:**
  - Designmatrix X hat vollen Spaltenrang (linear unabhängige Spalten)

- **Schätzer:**
  - Modellkoeffizienten: $\hat{\beta} = {(X^TX)}^{-1} X^TY$
  - Varianzparameter: $\hat{\sigma}^2 = \frac{1}{n - (p + 1)}\sum_{i=1}^n{(y_i - (X\hat{\beta})_i)^2}$

- **Standardfehler und Parametersigniﬁkanz im linearen Modell**
  - $\hat{\beta} \sim N(\beta, \sigma^2(X^TX)^{-1})$
  - $(n-(p+1)) \hat{\sigma}^2 \sim \sigma \chi^2_{n-(p+1)}$

- **Kovarianzmatrix:**
  - $Cov(\hat{\beta}) = \sigma^2(X^TX)^{-1}$
  - Schätzung: $Cov(\hat{\beta}) = \hat{\sigma}^2 (X^TX)^{-1}$
  - Benötigt für statistische Tests der Regressionskoeffizienten
  - Zusammenhang: $\frac{1}{\sigma^2} \sum_{i=1}^n (y_i - (X \hat{\beta})_i)^2 \sim \chi^2_{n-(p+1)}$

- **Konfidenzintervalle:**
  - Standardfehler $\beta_j$: $se(\hat{\beta}_j) = \hat{\sigma} \sqrt{(X^TX)^{-1}_{jj}}$
  - Standardisierter Koeffizient: $z_j = \frac{\hat{\beta}_j}{se(\hat{\beta}_j)}$ mit $z_j \sim t(n-(p+1))$
  - Konfidenzintervall: $\hat{\beta}_j \pm t_{n-p-1,1-\alpha/2} \cdot se(\hat{\beta}_j)$

- **Statistische Tests:**
  - Wichtigkeit einer Variable: Nullhypothese $H_0: \beta_j = 0$ gegen $H_a: \beta_j \neq 0$
  - Funktionaler Zusammenhang: Nullhypothese $H_0: \beta_1 = \beta_2 = ... = \beta_p = 0$ gegen $H_a$: Mindestens ein $\beta_j \neq 0$
  - Unter Nullhypothese: Kovariablen haben keinen Einfluss, $\hat{\beta_0} = \bar{y}$
  - Teststatistik: $F = \frac{(TSS - RSS) / p}{RSS / (n-p-1)}$ mit $F \sim F_{p, n-p-1}$
  
- **Standardisierte Residuen:**
  - Residuen messen den Abstand zwischen Beobachtung und geschätzter Regressionsgerade.
  - Berechnung: $\hat{\epsilon} = y - \hat{y} = y - X \hat{\beta}$

- **Homoskedastizität:**
  - Residuen sind oft nicht homoskedastisch.
  - Varianz der Residuen: $Var(\hat{\epsilon}_i) = \sigma^2 (1 - h_{ii})$
  - Standardisierte Residuen: $r_i = \frac{\hat{\epsilon}_i}{\hat{\sigma} \sqrt{1 - h_{ii}}}$

- **Modellüberprüfung:**
  - Beispiel: Residuen für Variablen horsepower und mpg
  - Plot zeigt klare Strukturen

- **Polynomiale Regression:**
  - Modell: $mpg = \beta_0 + \beta_1 \cdot horsepower + \beta_2 \cdot horsepower^2 + \epsilon$
  - Reduktion des Residuen-Trends und der Streuung
  - Q-Q-Plot zur Prüfung der Normalverteilung

- **Transformationen:**
  - Bei nichtlinearem Verhalten: z.B. $\ln(X)$ oder $\sqrt{X}$

- **Erweiterung des Modells:**
  - Weitere Variablen hinzufügen, z.B. weight:
    - Modell: $mpg = \beta_0 + \beta_1 \cdot horsepower + \beta_2 \cdot weight + \epsilon$

- **Kategorielle Variablen:**
  - Dummy-Variable für Geschlecht:
    - $x_i = 1$ (weiblich), $x_i = 0$ (männlich)
    - Modell: $y_i = \beta_0 + \beta_1 x_i + \epsilon_i$ (weiblich)
    - Modell: $y_i = \beta_0 + \epsilon_i$ (männlich)
	
## 6.3.3 Binäre Regression

- **Lineare Regressionsmodelle**:
  - Eignen sich für stetige oder kategorielle Zielvariablen.
  - Normalverteilung ist oft gerechtfertigt.

- **Problem bei binären Zielvariablen**:
  - Lineares Modell: $P(Y_i = 1) = \beta_0 + \beta_1 x_{i1} + \ldots + \beta_p x_{ik} + \epsilon_i$ ist ungeeignet.
  - Rechte Seite der Gleichung ist nicht binär und Wertebereich ist nicht beschränkt.
  - Fehlervarianz $Var(\epsilon_i)$ kann nicht homoskedastisch sein.
  - $Y_i$ ist Bernoulli-verteilt mit $\pi_i = \beta_0 + \beta_1 x_{i1} + \ldots + \beta_p x_{ip}$.
  - $\text{Var}(Y_i) = \pi_i (1 - \pi_i)$ hängt von Kovariaten ab.

- **Erwartungswert und Betrugserkennung**:
  - Erwartungswert als Linearkombination der Prädiktoren.
  - Beispiel: Betrugserkennung, $y_i=1$ für Betrug, $y_i=0$ für kein Betrug.

- **Binäre Regression**:
  - Schätzung des Effekts der Kovariablen auf die Wahrscheinlichkeit $\pi_i = P(Y_i = 1 \mid x_{i1}, \ldots, x_{ip})$.
  - Linearkombination der Prädiktoren: $\eta_i = \beta_0 + \beta_1 x_{i1} + \ldots + \beta_p x_{ip}$.
  - Verknüpfung mit Wahrscheinlichkeiten: $\pi_i = h(\eta_i)$.
  - $h$ ist eine streng monoton wachsende Verteilungsfunktion, $h(\eta) \in [0, 1]$.
  - Umkehrfunktion $g = h^{-1}$: $\eta_i = g(\pi_i)$.

- **Logit-Modell (logistische Regression)**:
  - Responsefunktion: $\pi = h(\eta) = \frac{\exp(\eta)}{1 + \exp(\eta)}$.
  - Linkfunktion: $g(\pi) = \log \left( \frac{\pi}{1 - \pi} \right) = \eta$.
  - Lineares Modell für die logarithmierten Chancen (log-odds): $\frac{\pi}{1 - \pi} = \exp(\beta_0) \exp(\beta_1 x_1) \cdot \ldots \cdot \exp(\beta_p x_p)$.
  - Interpretation: Erhöhung von $x_i$ um 1 multipliziert den Quotienten $\frac{\pi}{1 - \pi}$ mit $exp(β_1)$.

- **Parameterschätzung**:
  - Maximum-Likelihood-Schätzung der Parameter $\beta$.
  - Likelihood-Funktion: $L(\beta) = \prod_{i=1}^{n} f(y_i \mid \beta; \mathbf{x}_i)$.
  - $Y_i \sim \text{Bernoulli}(1, \pi_i)$ mit $\pi_i = P(Y_i = 1) = E(Y_i)$.
  - Dichtefunktion: $f(y_i \mid \pi_i) = \pi_i^{y_i} (1 - \pi_i)^{1 - y_i}$.
  - Log-Likelihood-Funktion: $\log L(\beta) = l(\beta) = \sum_{i=1}^{n} \left( y_i \log(\pi_i) - y_i \log(1 - \pi_i) + \log(1 - \pi_i) \right)$.
  
  ## 6.3.4 Generalisierte Additive Modelle (GAM)

- Die bisher dargestellten Regressionsmethoden basieren auf einem linearen Modell: $y_i = \beta_0 + \beta_1 x_{i1} + \ldots + \beta_p x_{ip} + \epsilon_i$.
- Dieses Modell ist oft nicht ausreichend, da die Realität oft nichtlineare Effekte enthält.
- Methoden wie verallgemeinerte lineare Modelle können Abhilfe schaffen.
- Auch Lasso (Abschnitt 6.6.10) und PCA (Abschnitt 6.5.2) verwenden lineare Modelle.
- Die Linearitätsannahme ist oft eine unzureichende Approximation.
- Ziel dieses Abschnitts:
  - Lösung von der Linearitätsannahme.
  - Erweiterung der Modellklasse für flexible nichtlineare Zusammenhänge.
- Erweiterung durch:
  - Ersetzen des linearen Terms $\beta_j x_{ij}$ durch eine „glatte“ Funktion $f_j(x_{ij})$.
  - Modell: $y_i = \beta_0 + \sum_{j=1}^{p} f_j(x_{ij}) + \epsilon_i$.
- Diese Modelle nennt man Generalisierte Additive Modelle (GAM).
  - Für jedes $X_j$ wird eine separate Funktion $f_j$ verwendet.
  - Die Annahme der Additivität bleibt bestehen.
  - Wirkung von $X_j$ auf Y kann individuell untersucht werden.
  - Nichtlineare Effekte können erfasst werden.
  - Interaktionen wie im linearen Fall sind möglich (z.B. $f_{jk}(X_j, X_k)$).
- Betrachtung einer metrischen Kovariable $z_i$:
  - Modell vereinfacht: $y_i = f(\mathbf{z}_i) + \epsilon_i$.
  - Fehler als unabhängig und identisch verteilt angenommen:
    - $E(\epsilon_i) = 0$
    - $\text{Var}(\epsilon_i) = \sigma^2$
  - Daraus folgt:
    - $E(y_i) = f(\mathbf{z}_i)$
    - $\text{Var}(y_i) = \sigma^2$

## 6.3.4.1 Polynom-Splines (Regressions-Splines)

- **Polynomiale Regression**
  - Bereits vorgestellt.
  - Berücksichtigt lineare und höhere Terme.
  - Polynom vom Grad l: $f(z) = \gamma_0 + \gamma_1 z + \ldots + \gamma_l z^l$.

- **Schätzung der Parameter**
  - Durchführung mit üblichen KQ-Schätzern.
  - Oft nicht ausreichend.

- **Beispiel: Polynomiale Modellierung**
  - Funktion: $f(x) = \sin(2x - 3) + 2e^{-10(x-1)^2}$.
  - Funktionswerte durch Störterm “verschmiert”.
  - Störterme normalverteilt: $N(0, 0.352)$.
  - Polynom (Grad 7) erfasst lokales Maximum schlecht.
  - Erhöhung des Polynomgrades verbessert Maximum, aber Modellierung wird “rau”.

- **Konstruktion von Polynom-Splines**
  - Bessere Modellierung durch Aufteilung des Wertebereichs in Intervalle.
  - Separate Schätzung in jedem Intervall.
  - Zusammengesetzte Funktion sollte “glatt” sein.
  - Polynom-Splines:
    - Funktion $f : [a, b] \to \mathbb{R}$.
    - Knoten: $a = \kappa_1 < \ldots < \kappa_m = b$.
    - Bedingungen:
      - $f(z)$ ist $(l - 1)$-mal stetig differenzierbar.
      - $f(z)$ ist auf Intervallen $[\kappa_j, \kappa_{j+1}]$ ein Polynom vom Grad $l$.

- **Definition**
  - Enthält keine Konstruktionsvorschrift.
  - Möglichkeit im folgenden Abschnitt vorgestellt.
  
 - **Polynom-Splines mit trunkierten Potenzen**
  - Darstellung von Polynom-Splines:
    - Polynome vom Grad $l$ mit Regularitätsanforderungen
  - Bekannte Vertreter:
    - Trunkierte Potenzen
    - Basic Splines (B-Splines)
  - Trunkierte Potenzen:
    - Darstellung: $y_i = \gamma_1 + \gamma_2 z_i + \ldots + \gamma_{l+1} z_i^l + \gamma_{l+2} (z_i - \kappa_2)^l + \ldots + \gamma_{l+m-1} (z_i - \kappa_{m-1})^l$

- **Eigenschaften der trunkierten Potenzen**
  - Verwendung individueller Polynome auf Intervallen
  - Erfüllung der Glattheitsbedingungen
  - Polynom vom Grad $l$ für Knoten $\kappa_2, \ldots, \kappa_{m-1}$:
    - $(z - \kappa_j)^l_+ = \begin{cases} (z - \kappa_j)^l & \text{wenn } z \geq \kappa_j, \\ 0 & \text{sonst}. \end{cases}$

- **Polynom-Splines als Linearkombination**
  - Polynom-Spline vom Grad $l$ und Knoten $\kappa_1 < \ldots < \kappa_m$ als Linearkombination:
    - $B_1(z) = 1, \quad B_2(z) = z, \quad \ldots, \quad B_{l+1}(z) = z^l$
    - $B_{l+2}(z) = (z - \kappa_2)_+^l, \quad \ldots, \quad B_d(z) = (z - \kappa_{m-1})_+^l$
  - Modell: $y_i = f(z_i) + \epsilon_i = \sum_{j=1}^{d} \gamma_j B_j(z_i) + \epsilon_i$

- **Parameterschätzung bei Polynom-Splines**
  - Bestimmung der Parameter $\gamma_j$ durch KQ-Schätzung
  - Designmatrix $Z$:
    $$Z = \begin{pmatrix} B_1(z_1) & \cdots & B_d(z_1) \\ \vdots & \ddots & \vdots \\ B_1(z_n) & \cdots & B_d(z_n) \end{pmatrix} =  \begin{pmatrix} 1 & z_1 & \cdots & z_1^l & (z_1 - \kappa_2)_+^l & \cdots & (z_1 - \kappa_{m-1})_+^l \\ \vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\ 1 & z_n & \cdots & z_n^l & (z_n - \kappa_2)_+^l & \cdots & (z_n - \kappa_{m-1})_+^l \end{pmatrix}$$
  - Modellgleichung: $\gamma = Z\gamma + \epsilon$
  - KQ-Schätzer: $\hat{\gamma} = (Z^T Z)^{-1} Z^T y$
  - Anmerkung:
    - B-Splines oft bevorzugt wegen numerischer Effizienz und Vermeidung von Gleitkommaüberläufen

- **Interpretation der Schätzwerte**
  - Interpretation der einzelnen Schätzwerte $\hat{\gamma}_j$ meist wenig sinnvoll
  - Güte der Modellanpassung in Streudiagramm mit geschätzter Kurve beurteilbar

- **Anzahl und Auswahl der Knoten**
  - Auswahl und Anzahl der Knoten entscheidend
  - Größere Knotenanzahl:
    - Flexiblere Schätzung
  - Kleinere Knotenanzahl:
    - Glattere Schätzung
  - Übliche Ansätze zur Knotenfestlegung:
    - Äquidistante Knoten im Intervall [a,b]:
      - $h = \frac{b - a}{m - 1}$ und $\kappa_j = a + (j - 1) \cdot h$
    - Quantilbasierte Knoten:
      - $\frac{j - 1}{m - 1}$-Quantile der beobachteten Kovariablenausprägungen $z_1, \ldots, z_n$
    - Visuelle Knotenwahl:
      - Anpassung der Knotendichte an Variabilität der Daten

## 6.3.4.2 Penalisierte Splines (P-Splines)

- **Güte der Schätzung mit Polynom-Splines**
  - Hängt stark von der Anzahl der Knoten ab.

- **Ansätze zur Verbesserung**
  - Adaptive Wahl der Knoten basierend auf Modellwahlstrategien.
  - Regularisierung durch Penalisierungsansätze.

- **Penalisierte Splines**
  - Verwendung einer großen Anzahl von Knoten (ca. 20-40) für Flexibilität.
  - Einführung eines zusätzlichen Terms in die Zielfunktion der Optimierung.
  - Bestrafung zu großer Variabilität zur Vermeidung von Überanpassung.
  - Übergang vom üblichen KQ-Kriterium zum penalisierten KQ-Kriterium:
    - $PKQ(\lambda) = \sum_{i=1}^{n} \left( y_i - \sum_{j=1}^{d} \gamma_j B_j(z_i) \right)^2 + \lambda \sum_{j=l+2}^{d} \gamma_j^2$

- **Glättungsparameter λ**
  - Verhindert zu starke Anpassung an die Daten.
  - Für $\lambda \rightarrow 0$:
    - Strafterm hat geringes Gewicht.
    - Schätzung liegt nahe am KQ-Schätzer.
  - Für $\lambda \rightarrow \infty$:
    - Strafterm dominiert.
    - Polynom vom Grad l als Schätzer für $f(z)$.
  - Position und Anzahl der Knoten spielen nur noch eine untergeordnete Rolle.

## 6.3.4.3 Glättungssplines (Smoothing Splines)

- **Betrachtung von Funktionenräumen**
  - Bisherige Basisfunktionen: TP- bzw. B-Splines.
  - Allgemeinere Annahme: Funktion $f$ ist zweimal stetig differenzierbar.
  - Kombination des Gütemaßes mit Penalisierungsterm:
    - $\sum_{i=1}^{n} (y_i - f(x_i))^2 + \lambda \int (f''(z))^2 \, dz$

- **Strafterm**
  - Zweite Ableitung als Maß für die Krümmung einer Funktion.

- **Lösung des Optimierungsproblems**
  - Spezielle Funktionenklasse: natürliche kubische Splines.

- **Natürliche kubische Splines**
  - Knotenmenge: $a < \kappa_1 < \ldots < \kappa_m < b$
  - Bedingungen für $f(z)$:
    - Kubischer Polynom-Spline zu obigen Knoten.
    - Randbedingungen: $f''(a) = f''(b) = 0$

## 6.3.5 Lineare Diskriminanzanalyse (LDA)

- **Lineare Diskriminanzanalyse (LDA)**
  - Methode zur Klassifikation diskreter Zielvariablen.
  - Ziel: Einteilung in möglichst überschneidungsfreie Gruppen anhand aussagekräftiger Merkmale.

- **Einführung der LDA**
  - **Bayes Theorem Ansatz**
    - Berechnung der bedingten Zähldichte: $p_k(x) = \frac{f_k(x) \pi_k}{\sum_{l=1}^{K} f_l(x) \pi_l}$
    - Diskrete Zielvariable Y mit Werten 1, ..., K in Abhängigkeit von $x \in \mathbb{R}^p$ Merkmalen.
    - $\pi_k = P(Y = k)$ und $f_k(x) = f(x|Y = k)$
    - Zuordnung jeder Beobachtung x zur Klasse $C_z(z=1, \ldots, K)$, wo $p_k(x)$ maximal ist.
  - **Linearkombinationen Ansatz**
    - Bildung von Linearkombinationen von $p_k(x)$.
    - Maximale Separation der Zentroiden der Datenverteilung bei gleichzeitiger Minimierung der inneren Varianz.
    - Projektion der Datensatz-Dimension auf wesentliche Freiheitsgrade (siehe Kapitel 6.5.1).

- **Annahmen und Optimierungsproblem**
  - Multivariate normalverteilte Beziehung von X unter Y = k in jeder Dimension.
  - Identische Kovarianzmatrix $\Sigma \in \mathbb{R}^{p \times p}$ für alle k.
  - Existenz des Erwartungswertes $\mu_k \in \mathbb{R}^p$.
  - Optimierungsproblem: $\delta_k(x) = x^T \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + \ln \pi_k$
  - Kritische Hinterfragung der Ergebnisse bei nicht normalverteilten Merkmalen.
  - Prüfung der reduzierten Kovarianzmatrix bei stark korrelierten Merkmalen.

- **Typischer LDA-Algorithmus**
  - Bestimmung der Schätzer $\hat{\pi}_k, \hat{\mu}_k, \hat{\Sigma}$ aus der Lernstichprobe $(x_1, y_1), \ldots, (x_n, y_n)$.
  - Zuweisung eines Samples $x \in \mathbb{R}^p$ zur Klasse $C_k = k$, für die der Ausdruck maximal ist.

- **Parameter und Fehlklassifikation**
  - $\hat{\pi}_k$: relative Häufigkeit von k in $y_1, \ldots, y_n$.
  - Schätzung der Parameter der multivariaten Normalverteilung.
  - Minimierung der Wahrscheinlichkeit einer Fehlklassifikation.
  
## 6.3.6 k-Nearest-Neighbors (kNN) 

- **k-Nächsten-Nachbarn (kNN) Algorithmus**
  - Simpel und oft erfolgreich.
  - Klassifikation anhand der k nächsten Nachbarn im Trainings-Datensatz.
  - Bei Gleichstand im Mehrheitsentscheid: zufällige Auswahl einer Klasse.

- **Relevante Elemente**
  - Trainingsset der klassifizierten Daten.
  - Distanzmaß.
  - Hyperparameter k (Anzahl der nächsten Nachbarn).

- **Vorgehensweise des kNN-Algorithmus**
  - **Abstandsberechnung**
    - Berechnung des Abstands zwischen Testobjekt $X_l$ und allen Trainingsobjekten $X_i$ mit Distanzmaß $d(X_l, X_i)$.
  - **Bestimmung der nächsten Nachbarn**
    - Auswahl der $k$ nächsten Nachbarn: $d(X_l, X_1) \leq d(X_l, X_2) \leq \cdots \leq d(X_l, X_k) \leq \cdots \leq d(X_l, X_n)$.
  - **Klassifizierung**
    - Klassifizierung des Testobjekts $X_l$ anhand der Häufigkeit der Klassen der $k$ nächsten Nachbarn:
      - $\arg\max_{z} \sum_{j=1}^{k} I(X_j \in C_z), \quad z \in \{1, \ldots, M\}$
      - mit Indikatorfunktion $I(\cdot)$.

## 6.3.7 Naive Bayes

- **Mehrfachklassifizierung**
  - Erfolgreich in der Dokumentklassifikation.
  - Zuordnung eines Textes zu Themenklassen wie Politik, Sport, Wirtschaft, Freizeit.
  - Codierung der Texte mit dem Bag-of-Words-Schema (siehe Abschnitt 5.1.5).

- **Trainingsdatensatz**
  - Gegeben: $(x_1, \ldots, x_N)$ mit $x_k \in \mathbb{R}^d \,(k = 1, \ldots, N)$.
  - Zugehörige Labels: $y_k \in \{C_1, \ldots, C_M\}$.
  - $C_1, \ldots, C_M$ repräsentieren die Klassen.

- **Zielsetzung**
  - Gegeben eine neue Beobachtung $x = (x_1, \ldots, x_d)^T \in \mathbb{R}^d$.
  - Bestimmung von $i$, sodass $p(C_i|x)$ maximiert wird.
  - Bayes-Theorem: $p(C_i|x) = \frac{p(x|C_i) \, p(C_i)}{p(x)}$
  - Maximierung von $p(x|C_i) \, p(C_i)$ bezüglich $i$ ausreichend.

- **Berechnung der Wahrscheinlichkeiten**
  - $p(C_i)$ als relative Häufigkeiten aus Trainingsdaten $\{y_i\}$.
  - Vereinfachende Annahme: $p(x|C_i) = \prod_{j=1}^{d} p(x_j|C_i)$.
  - Randverteilungen aus Trainingsdaten schätzen:
    - **Diskrete Merkmale $x_j$**: $p(x_j = M_k|C_i)$ über relative Häufigkeiten in $\{x_{ij}|y_i = C_i\}$.
    - **Kontinuierliche Merkmale $x_j$**: Verwendung eindimensionaler Verteilungen (Normalverteilung, Gleichverteilung, Kernel-Dichte-Schätzer).

- **Vorteile der Methode**
  - Gute und nachvollziehbare Ergebnisse in vielen Zusammenhängen.
  - Schnelle Durchführung der Analyse.
  - Einfache und intuitive Erfassung der Ergebnisse.

## 6.3.8 Entscheidungsbäume

- **Entscheidungsbäume im überwachten Lernen**
  - Basieren auf Entscheidungsbäumen.
  - Gegeben: N Beobachtungen $((x_1, y_1), \ldots, (x_N, y_N))$.
  - Separierung in Features $x_i$ und Labels $y_i$.
  - Featureraum $\mathbb{F}$ ist M-dimensional.
  - Ziel: Funktion $f$ finden mit $y_i \approx f(x_i)$.
  - Schätzung des Labels $y$ durch $\hat{y} = f(x)$.

- **Regressions- und Klassifikationsbäume**
  - **Regressionsbäume**: Reelle Labels $y \in \mathbb{R}$.
  - **Klassifikationsbäume**: Kategorielle Labels $y \in \{C_1, \ldots, C_N\}$.
  - Vorgehen in beiden Fällen ähnlich.

- **Vorhersagemodelle und Genauigkeit**
  - Einzelne Entscheidungsbäume: Schwache Vorhersagegenauigkeit.
  - Hohe Varianz: Änderungen in Trainingsdaten führen zu unterschiedlichen Vorhersagen $\hat{y}$.
  - Nutzung: Identifikation der aussagekräftigsten Features.
  - Bestandteil von Weiterentwicklungen: Random Forests und Gradient Boosting (siehe Abschnitte 6.3.9 und 6.3.10).

- **Zusammenhang Vorhersagegenauigkeit und Varianz**
  - Zerlegung des Regressionsmodells $\hat{f}(x)$:
    - $E[(y - \hat{f}(x))^2] = \text{Var}[\hat{f}(x)] + \text{Bias}[\hat{f}(x)] + \text{Irreduzibler Fehler}$
  - Hohe Varianz von $\hat{f}$ führt zu hoher Ungenauigkeit in der Vorhersage.

- **Beliebte Algorithmen für Entscheidungsbäume**
  - **CART-Algorithmus**:
    - Entwickelt von Leo Breiman et al. (1983).
    - Beispiele basieren auf CART.
  - **C5.0-Algorithmus**:
    - Aufgebaut auf C4.5 und ID3.
    - Ähnliche Vorhersagegenauigkeit wie CART.
    - Unterschiede in der Theorie werden an entsprechenden Stellen erläutert.

- **Konstruktion von Entscheidungsbäumen**
  - **Grundprinzip**
    - Funktion $y = f(x)$ ist stückweise konstant auf Quadern im Featureraum.
    - Ausgangsquader $R_0$ wird in kleinere Quader zerlegt.
    - Zerlegung erfolgt durch Schnitte mit achsenparallelen Hyperebenen.
    - Nicht alle Zerlegungen von $R_0$ sind möglich (siehe Abbildung 6.29).

  - **Ziel**
    - Featureraum $\mathbb{F}$ in Quader $R_1, R_2, \ldots, R_J$ unterteilen.
    - Labels $y_j$ sollen in den Quadern homogen verteilt sein.

  - **Vorhersagefunktion**
    - Innerhalb jeder Region konstant: $f(x) = c_j$ für $x \in R_j$.
    - Konstanten $c_j$ minimieren die Verlustfunktion auf den Trainingsdaten.
    - Verlust misst die Abweichung der Vorhersagen $\hat{y}_i = f(x_i)$ von den Labels $y_i$.

  - **Verlustfunktion**
    - **Klassifikationsbäume**: $L = \frac{1}{N} \sum_{i} I(y_i \neq \hat{y}_i)$ (Misclassification Rate)
    - **Regressionsbäume**: $L = \frac{1}{N} \sum_{i} (y_i - \hat{y}_i)^2$ (Mean Squared Error)

  - **Optimale Wahl von $c_j$**
    - **Klassifikationsbäume**: $c_j = \arg\max_k p_k(R_j)$ (Mehrheitswahl in $R_j$)
    - **Regressionsbäume**: $c_j = E(y_i|x_i \in R_j)$ (Durchschnitt in $R_j$)
    - $p_k(R_j)$: relativer Anteil von Klasse $C_k$ in Region $R_j$.

- **Bemerkung**
  - Greedy-Algorithmus: trifft lokal optimale Entscheidungen, revidiert keine früheren Entscheidungen.
  - Verwendet in CART- und C5.0-Algorithmen.
  - Optimale Regionszerlegung ist zu komplex für direkte Lösung.
  - C5.0-Algorithmus: multiple Splits bei kategoriellen Variablen.
  - CART-Algorithmus: nur binäre Splits.

## 6.3.9 Random Forests

- **Random Forest**
  - Methode des überwachten Lernens (Supervised Learning).
  - Trainingsdatensatz: $n$ Beobachtungen $(x_1, y_1), \ldots, (x_n, y_n)$.
  - Features $x_i$ und Labels $y_i$ im $p$-dimensionalen Feature-Raum $\mathbb{F}$.
  - Labels: numerisch $y \in \mathbb{R}$ oder kategoriell $y \in \{C_1, \ldots, C_k\}$.

- **Ensemblemethode**
  - Basierend auf Entscheidungsbäumen.
  - Einzelne Entscheidungsbäume: hohe Varianz und schwache Vorhersagegenauigkeit.
  - Random Forest: nutzt ein Ensemble von Bäumen zur Reduzierung der Varianz.

- **Ziel des Random-Forest-Algorithmus**
  - Senkung der Varianz durch ein Ensemble von Bäumen.
  - Vermeidung von großen Veränderungen in den Vorhersagen $\hat{y}$ bei neuen Trainingsdaten.

- **Verwendete Methoden**
  - **Bagging** (siehe Abschnitt 6.3.9.1)
  - **Random Subset Selection** (siehe Abschnitt 6.3.9.2)

### 6.3.9.1 Bagging

- **Varianzreduktion durch Mittelung**
  - Varianz $\sigma^2$ einer Zufallsvariable $Y$ kann auf $\sigma^2 / B$ gesenkt werden.
  - Dies erfolgt durch den Durchschnitt $\text{Avg}(Y) = \frac{1}{B} \sum_{i=1}^{B} Y_i$ von $B$ unabhängigen Versionen von $Y$.
  - Bei $B$ Bäumen und Mittelung der Vorhersagen wird diese Methode zur Varianzreduktion angewendet.
  - Eine Möglichkeit zur Generierung der Bäume: Bootstrap Aggregation (Bagging).

- **Algorithmischer Ablauf**
  - **Bootstrapping**
    - Ziehe $n$ Beobachtungen mit Zurücklegen aus dem Trainingsdatensatz.
    - Erzeuge neuen Trainingssatz $(x_1^{*b}, y_1^{*b}), \ldots, (x_n^{*b}, y_n^{*b})$.
    - Wiederhole den Prozess $B$ Mal (z.B. $B = 1000$).
  - **Erzeugung von Entscheidungsbäumen**
    - Fitte einen Entscheidungsbaum mit jedem neuen Trainingssatz.
    - Bestimme die Vorhersage $\hat{f}^{*b}(x)$.
    - Es entstehen $B$ Bäume und $B$ Vorhersagen.
  - **Finale Vorhersage**
    - **Regression**: Durchschnitt der Vorhersagen $\hat{f}_{\text{bag}}(x) = \frac{1}{B} \sum_{b=1}^{B} \hat{f}^{*b}(x)$.
    - **Klassifikation**: Mehrheitswahl der Klasse, die am häufigsten durch $\hat{f}^{*b}(x)$ vorhergesagt wird.
    - Alternativ: Bestimmung der Klassenwahrscheinlichkeiten durch relative Anteile in den $B$ Vorhersagen.

### 6.3.9.2 Random Subset Selection

- **Vorhersagen durch Bootstrapping**
  - Vorhersagen $\hat{f}^{*b}(x)$ sind oft nicht unabhängig.
  - Grund: Gebootstrapte Entscheidungsbäume sind sich meist sehr ähnlich.
  - Dominierende Features treten häufig in den ersten Splits auf.

- **Konsequenzen**
  - Senkung der Varianz der Vorhersage ist begrenzt.
  - Vorhersagegenauigkeit wird nicht signifikant erhöht.

- **Ähnliches Problem im Versicherungsumfeld**
  - Abhängige Risiken schwächen Diversifikationseffekte.
  - Beispiel in Abschnitt 4.2.2.2 verdeutlicht dies.

- **Lösung: Random Subset Selection im Random-Forest-Verfahren**
  - Ziel: Reduzierung der Ähnlichkeit zwischen den Bäumen.
  - Vorgehen:
    - Bei jedem Split wird eine zufällige Teilmenge von m Features aus insgesamt p Features ausgewählt.
    - Auswahl der Features erfolgt bei jedem Split neu durch (Pseudo-)Zufall.
    - Typische Wahl für m: $m = \sqrt{p}$.

- **Ergebnis**
  - Weniger dominante Features werden berücksichtigt.
  - Ensemble enthält Bäume, die sich in ihrer Struktur deutlich unterscheiden.

## 6.3.10 Boosting

- **Boosting**
  - Familie von Ensemblemethoden.
  - Ziel: Kombination mehrerer schwacher Prädiktoren zur Verbesserung der Vorhersage.

- **Vorgehen**
  - Konstruktion einer Folge von Vorhersagemodellen (base learners).
  - Fokus auf Samples mit schlechten Vorhersagen durch bereits konstruierte Modelle.
  - **Adaptives Gewichtungsschema**
    - Hohe Gewichte für schlecht vorhergesagte Samples.
    - Niedrige Gewichte für gut vorhergesagte Samples.
  - **Alternativ: Bootstrapping**
    - Gewichtetes Ziehen mit Zurücklegen.
    - Führt zum AdaBoost-Algorithmus.
  - Festlegung einer Vorschrift zur Kombination der Vorhersagen.

- **Weitere Boosting-Varianten**
  - Gemeinsames Konstruktionsprinzip: iterative Minimierung eines Fehlermaßes.

- **Grundlagen**
  - Trainingsdatensatz: $(x_n, y_n)_{n=1,\ldots,N}$.
  - Familie von Lernalgorithmen $\mathcal{B}$ für base learners.
  - Ziel: Konstruktion einer Folge $f^m = \sum_{k=1}^{m} \alpha_{k}^{m} g_{k}^{m}$ mit $\alpha_{k}^{m} \in \mathbb{R}$ und $g_{k}^{m} \in \mathcal{B}$.

- **Güte der Approximation**
  - Gemessen durch Verlustfunktion $L : \mathbb{R} \times \mathbb{R} \to \mathbb{R}$.
  - Formel: $L(f) = \sum_{n=1}^{N} L(y_n, f(x_n))$.

- **Beispiele für Verlustfunktionen**
  - Quadratischer Fehler: $L_1(x, y) = (x - y)^2$
  - Exponential loss: $L_2(x, y) = \exp(-yx)$

- **Boosting: Grundprinzip**
  - Ziel: Kombination mehrerer schwacher Prädiktoren zur Verbesserung der Vorhersage.
  - Abfolge von Vorhersagemodellen (base learners).

- **Iterative Konstruktion**
  - Neue Modelle fokussieren auf schlecht vorhergesagte Samples.
  - Anpassung durch adaptive Gewichte oder Bootstrapping (führt zu AdaBoost).

- **Formel und Minimierung**
  - Folge $f^m = f^{m-1} + \alpha^m g^m$ mit $\alpha^m \in \mathbb{R}$ und $g^m \in \mathcal{B}$.
  - Minimierung des Ausdrucks $(\alpha, \gamma) \mapsto \sum_{n=1}^{N} L(y_n, f^{m-1}(x_n) + \alpha b_\gamma(x_n))$.

- **Verlustfunktion**
  - Quadratischer Fehler $L_1$: $(\alpha, \gamma) \mapsto \sum_{n=1}^{N} \left( y_n - f^{m-1}(x_n) - \alpha b_\gamma(x_n) \right)^2$.
  - Exponential loss $L_2$: führt zu AdaBoost bei $y_k \in \{-1, 1\}$.

- **Gradient Boosting**
  - Iterative Minimierung eines Fehlermaßes durch Gradientenabstieg.
  - Schritt 1: Minimierung des Ausdrucks $(\alpha, z_1^m, \ldots, z_N^m) \mapsto \sum_{n=1}^{N} L(y_n, f^{m-1}(x_n) + \alpha z_n^m)$.
  - Schritt 2: Lösung von $b^m = \arg\min_{b \in \mathcal{B}} \sum_{i=1}^{N} (z_i - b(x_i))^2$.
  - Schritt 3: Wahl von $\alpha^m$ durch eindimensionale Suche zur Minimierung von $\alpha^m \mapsto \sum_{n=1}^{N} L(y_n, f^{m-1}(x_n) + \alpha^m b^m(x_n))$.
  - Einführung der Lernrate $\eta$: $f^m = f^{m-1} + \eta \alpha^m b^m$.

- **Hyperparameter und Performanz**
  - Typ des Basismodells frei wählbar.
  - Gebräuchlich: Bäume mit ein oder zwei Verzweigungsebenen (decision tree stumps).
  - Flache Bäume sind performanter und korrespondieren mit niedrigeren Interaktionstermen.
  - Tiefe der Bäume: Hyperparameter, der validiert werden sollte (siehe Abschnitt 6.6.3).

## 6.3.11 Support Vector Machines

- **Support Vector Machines (SVM)**
  - Methode des statistischen Lernens
  - Ursprünglich für binäre Klassifizierungsprobleme
  - Varianten für:
    - Klassifizierungsprobleme mit n Klassen
    - Regressionsaufgaben
  - Anwendungen jenseits des überwachten Lernens:
    - Dimensionsreduktion
    - Clustering

- **Grundidee**
  - Daten mittels optimaler Hyperebene separieren
  - Nichtlineare Transformationen durch Kernelfunktionen
  - Anwendbar auch bei nicht linear separierbaren Daten

- **Einfaches Beispiel**
  - Synthetischer Datensatz mit 50 Punkten (Abbildung 6.34)
  - Finden einer Hyperebene (Gerade), die Punktwolken trennt
  - Klassenzugehörigkeit durch Position zur Geraden bestimmen
  - Aufteilung des Raumes durch SVM (Abbildung 6.35)

- **Datensatz**
  - Form: $\{(x_i, y_i) \mid i = 1, \ldots, m; \, y_i \in \{-1, 1\}\}$
  - Beobachtungen: Zwei Klassen $C^+$ und $C^-$ (je nachdem ob $y_i = +1$ oder -1)

- **Lineare Separierbarkeit**
  - Klassen sind linear separierbar, wenn ihre konvexen Hüllen sich nicht schneiden
  - Hyperebene trennt die Klassen mit maximalem euklidischen Abstand
  - Gleichung der Hyperebene: ⟨w, x⟩+b = 0
    - Parameter: w (Normalenvektor), b (Bias)
  - Ziel: Abstand (Margin) maximieren

- **Lösung**
  - Minimierung von $\frac{1}{2} \|w\|^2$ unter Bedingung $y_i(\langle w, x_i \rangle + b) \geq 1$ für alle $1 \leq i \leq m$
  - Quadratisches Minimierungsproblem mit linearen Nebenbedingungen

- **Allgemeiner Fall**
  - Unterschreitungen der Abstandssumme und Fehlklassifikationen zulässig
  - Minimierung von $f(w) = \frac{\|w\|^2}{2} + C \left( \sum_{i} \xi_i \right)^k$
    - $\xi_i \geq 0$: Unterschreitung der Abstandssumme ($0 < \xi_i \leq 1$) bzw. Fehlklassifikation ($\xi_i > 1$)
  - Parameter C und k: Hyperparameter

- **Numerische Lösung**
  - Meist über die duale Form
  - Duales Problem: Siehe [91] für Details

- **Verallgemeinerung**
  - Nichtlineare Transformation der Featuredatensätze
  - Verwendung von Kernelfunktionen zur linearen Separierbarkeit
 
## 6.3.12 Künstliche Neuronale Netze und Deep Learning

- **Künstliche Neuronale Netze (KNN)**
  - Ursprung: Einfaches Modell biologischer Systeme
  - **Biologisches Vorbild**
    - Nervenzellen (Neuronen) interagieren über Verbindungen (Synapsen)
    - Austausch von elektrischen oder chemischen Signalen
    - Neuronen haben ein- und ausgehende Verknüpfungen
    - Neuron sendet ein Ausgangssignal, wenn Eingangssignale Grenzwert überschreiten
  - **Funktionsweise**
    - Einzeln interagierende Neuronen bilden ein Gesamt-System
  - **Entwicklung**
    - KNN basieren auf dem biologischen Modell
    - Werden in diesem Abschnitt besprochen

### Aufbau und Funktionsweise

- **Repräsentation eines KNN**
  - KNN als gerichteter Graph
    - Knoten: Künstliche Neuronen
    - Kanten: Verbindungen zwischen Neuronen
  - **Funktion eines Neurons**
    - $y = f_w(x_1, \ldots, x_n) = s \left( w_0 + \sum_{j=1}^{n} w_j x_j \right)$
    - $s$: Aktivierungsfunktion ($s : \mathbb{R} \to \mathbb{R}$)
    - $w$: Gewichtsvektor ($w_0, \ldots, w_n$)
    - Eingangssignale: $(x_1, \ldots, x_n)$
    - Ausgabe: $y$

- **Aktivierungsfunktionen**
  - Historisch: $s(x) = \begin{cases} 1, & \text{falls } x \geq 0 \\ 0, & \text{sonst} \end{cases}$
  - Heutzutage: Glatte Funktionen, einfach zu berechnen
  - Typische Funktionen: Siehe Tabelle 6.5

- **Perzeptron**
  - Einfachstes KNN mit einem Neuron
  - Grafische Darstellung: Abbildung 6.36
  - Entwickelt Ende der 50er Jahre zur binären Klassifizierung ([78])

- **Größere neuronale Netze**
  - Konstruktion aus Perzeptronen
  - Gruppierung in Schichten (layers)
  - Bestimmung der Ergebniswerte $y$ bei Eingangssignal $x$
  - Beispiel: Abbildung 6.37
  - **Vollständige Schicht (dense layer)**
    - Verknüpfung aller $n_k$ Neuronen der $k$-ten Schicht mit $n_{k-1}$ Neuronen der $(k-1)$-ten Schicht
    - $(n_{k-1} + 1) n_k$ Gewichtsparameter

- **Anwendungen von KNNs**
  - Verschiedene Aufgaben des maschinellen Lernens
  - **Überwachtes Lernen**
    - Regressions- und binäre Klassifikationsaufgaben
      - Netze mit einem terminalen Neuron
      - Aktivierungsfunktion des terminalen Neurons: sigmoid (siehe Tabelle 6.5) oder Identität
    - Klassifikationsaufgaben mit $k$ Klassen
      - Terminale Schicht mit $k$ Neuronen und Identität als Aktivierungsfunktion
      - Standardisierung der Ausgangswerte mittels softmax (siehe Tabelle 6.5)

- **Deep Learning**
  - Verwendung von Netzen mit vielen Schichten und Neuronen
  - Viele freie Parameter
  
- **Lernverfahren**
  - Gradientenabstiegsmethode
  - Backpropagation-Algorithmus (siehe Abschnitt 6.3.12.1)
  - Durchbrüche ab 2010 bei Solvern (vgl. [17])
  - Aufschwung der Künstlichen Intelligenz (siehe Abschnitt 9.1)

- **Anwendungen von KNNs/Deep Learning**
  - **Pricing und Reserving**
    - Einsatz bei speziellen Schadenversicherungen auf Einzelrisikobasis
    - Unverzerrte Ergebnisse auf aggregierter Ebene (vgl. [107])
  - **Kapitalanlagesteuerung**
    - Untersuchung komplexer Einflüsse mit mehrschichtigen neuronalen Netzen
    - Auswirkungen auf Eigenmittelposition unter Solvency II (vgl. [20])
  - **Klassische Prognosemodelle**
    - Herausforderung: Transparente Ergebnisse zur Überzeugung von Regulierern

- **Konstruktion von neuronalen Netzen mit Keras**
  - Keras bietet Abstraktionen für KNNs
  - Nutzung von Tensorflow oder CNTK im Hintergrund
  
- **Beispiel: Einfaches Netz mit Keras**
  ```python
  from tensorflow import keras
  # Eingangsdaten beschreiben: 5 Komponenten
  input_tensor = keras.layers.Input(shape=(5,))
  # Innere Schicht mit 10 Neuronen
  dense_layer = keras.layers.Dense(units=10, activation='relu')(input_tensor)
  # Ausgangsschicht mit einem Neuron
  output_tensor = keras.layers.Dense(units=1, activation='sigmoid')(dense_layer)
  # Konstruktion des Modells
  model = keras.models.Model(inputs=input_tensor, outputs=output_tensor)
  ```

  - **Parameter**
    - Innere Schicht: 6 Parameter pro Neuron
    - Ausgangsneuron: 11 Parameter
    - Insgesamt: 71 Parameter
    - Parameter müssen durch Training eingestellt werden

  - **Vorhersage mit zufälligen Daten**
  ```python
  import numpy as np
  # Erzeuge zehn zufällige Datensätze
  data = np.random.rand(10, 5)
  predictions = model.predict(data)
  ```

  - Numpy-Array `predictions` enthält Vorhersagen der Form (10,1)

### 6.3.12.1 Training von Neuronalen Netzen

- **Lernen bei KNN**
  - Einstellung der Gewichte jedes Neurons
  - Besondere Schwierigkeit: Innere Schichten ohne explizite Trainingsdaten
  - Netz als Ganzes trainieren
  - Verwendung eines Gradientenabstiegsverfahrens im Raum aller Koeffizienten

- **Herleitung der Aktualisierungsgleichungen**
  - Ausgangspunkt: Netz mit einem terminalen Neuron
  - Netz besteht aus n Schichten
  - Neuronen der m-ten Schicht: $(N_1^{(m)}, \ldots, N^{(m)}_{L_m})$
  - Trainingsdaten-Menge: $B = \{(x_i, y_i) \mid i = 1, \ldots, K\}$
  - Training in Batches zur Effizienzsteigerung

- **Notation und Operation eines Neurons**
  - Betrachte Neuron $N_k^{(m)}$ der m-ten Schicht
  - Output auf dem i-ten Trainingssample: $x_k^{(m),i}$
  - Operation des Neurons: 
    - $z_{(km),i} = w_{(km,0)} + \sum_{j=1}^{Q_k} w_{(km,j)} x_{(jm-1),i}$
    - $x_{(km),i} = \sigma(z_{(km),i})$
  - $(x_j^{(m-1),i})_{j=1,\ldots,Q_k}$: Eingänge des Neurons $N_k^{(m)}$ auf dem $i$-ten Trainingssample
  - $(w_{k,j}^{(m)})_{j=0,\ldots,Q_k}$: anzupassende Parameter
  - Aktivierungsfunktion $\sigma$ kann vom jeweiligen Neuron abhängen

- **Vorbereitung**
  - Initialisierung aller Koeffizienten des Netzes mit Pseudozufallszahlen nahe 0

- **Erster Schritt**
  - Generierung der Vorhersagen des terminalen Neurons $(x_1^{(n),i})_{i=1,\ldots,K}$
  - Jeder Trainingspunkt $x_i$ wird einmal durch das gesamte Netz geschickt

- **Fehlerberechnung**
  - Fehler für den Batch: $E(w) = \frac{1}{2} \sum_{i=1}^{K} (y_i - x_{1(n),i})^2$
  - Vereinfachung: Mittlerer quadratischer Fehler
  - Parametervektor $w$ umfasst alle Koeffizienten des Netzes

- **Gradientenabstieg**
  - Ziel: Minimierung des Fehlers $E$
  - Methode: Backpropagation
  - Bestimmung der partiellen Ableitungen: $\frac{\partial E_i}{\partial w_{(km,j)}}$ für alle Koeffizienten $w_{(km,j)}$
  - Verallgemeinerte Fehlergrößen: $\delta_{(km),i} := \frac{\partial E_i}{\partial z_{(km),i}}$

- **Kettenregel**
  - Ableitungen: $\frac{\partial E_i}{\partial w_{k,j}^{(m)}} = \delta_k^{(m),i} x_j^{(m-1),i}$ mit $x_0^{(m-1),i} = 1$

- **Verallgemeinerte Fehler $\delta_k^{(m),i}$**
  - Terminale Schicht: $\delta_1^{(n),i} = (y_i - x_1^{(n),i}) \sigma' (z_1^{(n),i})$
  - Rückwärts-Transport des Fehlers
    - Neuronen der Folgeschicht $(N_{k_1}^{(m+1)}, \ldots, N_{k_l}^{(m+1)})$
    - $\delta_k^{(m),i} = \sum_{r=1}^{l} \delta_{k_r}^{(m+1),i} w_{k_r,k}^{(m+1)} \sigma'(z_k^{(m),i})$

- **Notation**
  - $w_{k_r,k}^{(m+1)}$: Koeffizient des Neurons $N_{k_r}^{(m+1)}$, der mit dem Eingang $x_k^{(m),i}$ verbunden ist

- **Berechnung der δ und des Gradienten**
  - Aus Gleichung (6.17) und Startwert (6.16): Berechnung aller δ
  - Ableitung des Gradienten ∇E(w) durch Zusammenhang (6.15)

- **Iterative Aktualisierung der Koeffizienten**
  - Abstiegsregel: $w_j \rightarrow w_j - \lambda \frac{\partial E(w)}{\partial w_j}$
  - Parameter λ (learning rate): 0 < λ ≤ 1
  - Einfluss der learning rate: Konvergenzgeschwindigkeit
  
- **Adaptive Anpassung der Learning Rate**
  - Wichtig für Konvergenz
  - Beispiel: Adam-Optimierungsmethode

- **Backpropagation**
  - Fehler wandern rückwärts durch das Netz (Gleichung 6.17)
  - Weitere Details: Siehe [13], Abschnitt 5.3

- **Maßnahmen zur Vermeidung lokaler Minima**
  - **Verschiedene Initialisierungen**
    - Unterschiedliche Vorbelegungen der Koeffizienten
  - **Anwendung von Momentum**
    - Update der Koeffizienten in Richtung des aktuellen Gradienten und der vorherigen Richtung
  - **Verwendung von Störanteilen in Trainingsdaten**
    - Verhindert Überanpassung
    - Vergrößert Trainingsbasis
    - Erzeugung gültiger Daten durch Störungen oder Transformationen (z.B. Bildrotationen)

## Bemerkung zum Training für komplexe Aufgaben:

- **Große Netze**
  - Erfolgreich für Bilderkennung und Spracherkennung
  - Benötigen viele Trainingsdaten und viel Rechenzeit

- **Transfer Learning**
  - Ansatz: Nutzung vortrainierter Netzwerke für spezielle Probleme
  - Nur die letzten Layer werden in der neuen Domäne neu trainiert
  - Problem: Anwendbarkeit erst nach Training erkennbar
  - Hoher Aufwand für geeigneten Transfer

- **Transparenz der Methode**
  - Zusatzaufwand wegen Regulatorik und Kundenakzeptanz

### 6.3.12.2 Netztopologien

- **Spezielle Architekturen**
  - **Recurrent Neural Networks (RNNs)**
    - Besonders geeignet für Zeitreihenanalyse
  - **Convolutional Neural Networks (CNNs)**
    - Details im nächsten Paragraphen

#### Convolutional Neural Networks

- **Convolutional Neural Networks (CNN)**
  - Erfolgreich im Bereich der Bilderkennung
  - Reduktion der Parameterzahl durch weight sharing (gleiche Gewichte für Gruppe von Neuronen)

- **Beispiel: Klassifikation zweidimensionaler Bilddaten**
  - Ziel: Lokale Eigenschaften in Bilddaten finden
  - **Convolutional Layer**
    - Bildausschnitte (Patches) durch Filter abgebildet
    - Beispiel: Monochromes Bild (30 × 30 Pixel), Patch (3 × 3 Pixel)
    - Ein Filter: 784 Kopien eines Neurons mit neun Eingängen und einem Biasparameter
    - Ergebnis: Bild der Dimension 28 × 28
    - Verschiebung des Filters über das Bild entspricht Faltungsoperation (convolution)

- **Training des Convolutional Layers**
  - Variante des Backpropagation-Algorithmus
  - Gemeinsames Update in Richtung des gemittelten Gradienten

- **Subsampling Layer**
  - Folgt auf Convolutional Layer
  - Ziel: Dimensionen reduzieren und lokale Translationsinvarianz erzeugen
  - Typische Variante: Max-Pooling
    - Zerlegt Ausgabe in Segmente der Dimension r × r (z.B. r = 2)
    - Pro Kanal wird Maximum im r × r-Bereich gebildet
    - Dimension der Ausgabe wird halbiert

- **Struktur eines CNN**
  - Paarweise Anordnung: Convolutional Layer gefolgt von Subsampling Layer
  - Abschluss: Dicht verknüpfte Ausgangsschicht

### 6.3.12.3 Zusammenfassung

- **Zusammenfassung von KNNs und deren Training**
  - **Architektur eines KNN**
    - Besteht aus mehreren Schichten von Neuronen
    - Trainingsdaten: Eingänge an der ersten Schicht
    - Ausgangsvektor der terminalen Schicht: liefert Antwort des Netzes
    - Dimensionierung: muss passen
  
  - **Schichttypen**
    - Verknüpfung von Neuronen einer Schicht k-1 mit Schicht k: legt Schichttyp fest
    - Häufig: vollständige Verknüpfung (dense layer)
    - Andere Muster: convolutional layer, subsampling layer
  
  - **Aktivierungsfunktion**
    - Festlegung für jedes Neuron notwendig
  
  - **Fehlermaß**
    - Auswahl erforderlich für das Training
  
  - **Trainingsparameter**
    - Optimierungsalgorithmus
    - Anzahl der Durchläufe (epochs)
    - Größe der Trainingsbatches

- **Erfolge und Überlegungen**
  - **Erfolge**
    - Beispiel: AlphaGo besiegt Go-Spieler Lee Sedol
  
  - **Überlegungen vor Einsatz**
    - Hohe Rechenlast beim Training
    - Alternative Methoden in Betracht ziehen: eventuell einfacher und erfolgreicher
